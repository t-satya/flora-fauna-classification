{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":84763,"databundleVersionId":9549185,"sourceType":"competition"}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-output":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-11-27T17:31:44.527759Z","iopub.execute_input":"2024-11-27T17:31:44.528027Z","iopub.status.idle":"2024-11-27T17:31:44.879660Z","shell.execute_reply.started":"2024-11-27T17:31:44.527992Z","shell.execute_reply":"2024-11-27T17:31:44.878903Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"## Library Imports","metadata":{}},{"cell_type":"code","source":"# Imports necessary for training the model\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\nimport torchvision.datasets as dsets\nimport torchvision.models as models\nimport torchvision.transforms as transforms\nimport torchvision.utils as utils\nfrom torch.utils.data import Dataset, DataLoader, random_split\nfrom tqdm import tqdm\n\n# Few other important libraries\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport time\nfrom sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n\ntorch.manual_seed(0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T17:31:44.880685Z","iopub.execute_input":"2024-11-27T17:31:44.881043Z","iopub.status.idle":"2024-11-27T17:31:48.083914Z","shell.execute_reply.started":"2024-11-27T17:31:44.881015Z","shell.execute_reply":"2024-11-27T17:31:48.082941Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"<torch._C.Generator at 0x7ffb9ecbae10>"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T17:31:48.085452Z","iopub.execute_input":"2024-11-27T17:31:48.086125Z","iopub.status.idle":"2024-11-27T17:31:48.091384Z","shell.execute_reply.started":"2024-11-27T17:31:48.086078Z","shell.execute_reply":"2024-11-27T17:31:48.090234Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# !pip install GPUtil\n\n# import torch\n# from GPUtil import showUtilization as gpu_usage\n# from numba import cuda\n\n# def free_gpu_cache():\n#     print(\"Initial GPU Usage\")\n#     gpu_usage()                             \n\n#     torch.cuda.empty_cache()\n\n#     cuda.select_device(0)\n#     cuda.close()\n#     cuda.select_device(0)\n\n#     print(\"GPU Usage after emptying the cache\")\n#     gpu_usage()\n\n# free_gpu_cache()                           \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T17:31:48.094762Z","iopub.execute_input":"2024-11-27T17:31:48.095505Z","iopub.status.idle":"2024-11-27T17:31:48.103958Z","shell.execute_reply.started":"2024-11-27T17:31:48.095459Z","shell.execute_reply":"2024-11-27T17:31:48.103053Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"## Data Augmentation","metadata":{}},{"cell_type":"code","source":"# Transform for Data Augmentation\ntransform_train = transforms.Compose([\n    transforms.Resize(256),                        # Resize to 256x256\n    transforms.RandomCrop(224),                     # Randomly crop to 224x224\n    transforms.RandomHorizontalFlip(0.5),           # Random horizontal flip with 50% probability\n    transforms.ToTensor(),                          # Convert the image to a PyTorch tensor\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize with ImageNet stats\n])\n\ntransform_test = transforms.Compose([\n    transforms.Resize(256),                    # Resize to 256x256 (same as training)\n    transforms.CenterCrop(224),                 # Center crop to 224x224\n    transforms.ToTensor(),                      # Convert to PyTorch tensor\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize with ImageNet stats\n])\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T17:31:48.105202Z","iopub.execute_input":"2024-11-27T17:31:48.105573Z","iopub.status.idle":"2024-11-27T17:31:48.116807Z","shell.execute_reply.started":"2024-11-27T17:31:48.105523Z","shell.execute_reply":"2024-11-27T17:31:48.115922Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"## Data Loading","metadata":{}},{"cell_type":"code","source":"train_path = \"/kaggle/input/deep-learning-practice-image-classification/train\"\ntest_path = \"/kaggle/input/deep-learning-practice-image-classification/test\"\n\n\n# Load Training and Test datasets\ntrain_data = dsets.ImageFolder(root=train_path, transform=transform_train)\n\nfrom PIL import Image  # Import the Image module from Pillow\n\nclass CustomTestDataset(Dataset):\n    def __init__(self, test_dir, transform=None):\n        self.test_dir = test_dir\n        self.transform = transform\n        self.image_paths = [os.path.join(test_dir, fname) for fname in os.listdir(test_dir)]\n    \n    def __len__(self):\n        return len(self.image_paths)\n    \n    def __getitem__(self, idx):\n        img_path = self.image_paths[idx]\n        image = Image.open(img_path).convert(\"RGB\")  # Open image and convert to RGB\n        if self.transform:\n            image = self.transform(image)  # Apply the transform if available\n        return image, img_path  # Return the image and its path\n\n# Create test data\ntest_data = CustomTestDataset(test_dir=test_path, transform=transform_test)\n\n# Print data details\nprint(\"Train Data Shape: \", len(train_data))\nprint(\"Test Data Shape: \", len(test_data))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T17:31:48.118145Z","iopub.execute_input":"2024-11-27T17:31:48.118451Z","iopub.status.idle":"2024-11-27T17:31:51.432897Z","shell.execute_reply.started":"2024-11-27T17:31:48.118414Z","shell.execute_reply":"2024-11-27T17:31:51.431754Z"}},"outputs":[{"name":"stdout","text":"Train Data Shape:  9999\nTest Data Shape:  2000\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# Create a validation set from the training data\ntrain_size_fraction = 0.9\ntrain_size = int(train_size_fraction*len(train_data))  # 90% for training\nval_size = len(train_data) - train_size  # 10% for validation\ntrain_dataset, val_dataset = random_split(train_data, [train_size, val_size])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T17:31:51.434006Z","iopub.execute_input":"2024-11-27T17:31:51.434304Z","iopub.status.idle":"2024-11-27T17:31:51.439796Z","shell.execute_reply.started":"2024-11-27T17:31:51.434276Z","shell.execute_reply":"2024-11-27T17:31:51.439085Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"print(\"label_mapping\",train_data.class_to_idx)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T17:31:51.441210Z","iopub.execute_input":"2024-11-27T17:31:51.441575Z","iopub.status.idle":"2024-11-27T17:31:51.453630Z","shell.execute_reply.started":"2024-11-27T17:31:51.441534Z","shell.execute_reply":"2024-11-27T17:31:51.452693Z"}},"outputs":[{"name":"stdout","text":"label_mapping {'Amphibia': 0, 'Animalia': 1, 'Arachnida': 2, 'Aves': 3, 'Fungi': 4, 'Insecta': 5, 'Mammalia': 6, 'Mollusca': 7, 'Plantae': 8, 'Reptilia': 9}\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"batch_size = 64 # Batch Size of the images\n\n# Creating dataloaders\ntrain_loader = DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle = True)\nval_loader = DataLoader(dataset = val_dataset, batch_size = batch_size, shuffle = False)\ntest_loader = DataLoader(dataset = test_data, batch_size = batch_size, shuffle = False)\n\n# Printing the no. of samples in each dataset\nprint(\"No. of samples in training dataset:\", len(train_loader.dataset))\nprint(\"No. of samples in validation dataset:\", len(val_loader.dataset))\nprint(\"No. of samples in test dataset:\", len(test_loader.dataset))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T17:31:51.454747Z","iopub.execute_input":"2024-11-27T17:31:51.455137Z","iopub.status.idle":"2024-11-27T17:31:51.465362Z","shell.execute_reply.started":"2024-11-27T17:31:51.455092Z","shell.execute_reply":"2024-11-27T17:31:51.464362Z"}},"outputs":[{"name":"stdout","text":"No. of samples in training dataset: 8999\nNo. of samples in validation dataset: 1000\nNo. of samples in test dataset: 2000\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"## Training and Validating Model ","metadata":{}},{"cell_type":"code","source":"from torchvision import models\nimport torch.nn as nn\nimport torch\nfrom tqdm import tqdm  # For a progress bar\nfrom sklearn.metrics import f1_score\n\n# Function to calculate accuracy\ndef calculate_accuracy(preds, labels):\n    correct = (preds == labels).sum().item()\n    return correct / len(labels) * 100\n\n# Define the training function\ndef train_model(model, train_loader, val_loader, num_epochs=10, learning_rate=0.0001,patience=5):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model = model.to(device)\n\n    # Loss function\n    criterion = nn.CrossEntropyLoss()\n\n    # Optimizer\n    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n\n    best_val_f1 = 0.0  # Track the best F1 score\n    best_model_weights = None  # Store best model weights\n\n    for epoch in range(num_epochs):\n        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n        print(\"-\" * 20)\n        \n        # Training phase\n        model.train()\n        running_loss = 0.0\n        running_corrects = 0\n        all_train_preds = []\n        all_train_labels = []\n\n        for inputs, labels in tqdm(train_loader):\n            inputs, labels = inputs.to(device), labels.to(device)\n\n            # Forward pass\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n\n            # Get predictions\n            _, preds = torch.max(outputs, 1)\n\n            # Backward pass\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n            running_loss += loss.item()\n            running_corrects += (preds == labels).sum().item()\n\n            all_train_preds.extend(preds.cpu().numpy())\n            all_train_labels.extend(labels.cpu().numpy())\n\n        # Calculate training accuracy and F1 score\n        train_accuracy = calculate_accuracy(torch.tensor(all_train_preds), torch.tensor(all_train_labels))\n        train_f1 = f1_score(all_train_labels, all_train_preds, average='weighted')\n\n        avg_train_loss = running_loss / len(train_loader)\n        print(f\"Train Loss: {avg_train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, Train F1: {train_f1:.4f}\")\n\n        # Validation phase\n        model.eval()\n        val_preds = []\n        val_labels = []\n        running_val_loss = 0.0\n        running_val_corrects = 0\n\n        with torch.no_grad():\n            for inputs, labels in val_loader:\n                inputs, labels = inputs.to(device), labels.to(device)\n                outputs = model(inputs)\n                loss = criterion(outputs, labels)\n\n                _, preds = torch.max(outputs, 1)\n\n                running_val_loss += loss.item()\n                running_val_corrects += (preds == labels).sum().item()\n\n                val_preds.extend(preds.cpu().numpy())\n                val_labels.extend(labels.cpu().numpy())\n\n        # Calculate validation accuracy and F1 score\n        val_accuracy = calculate_accuracy(torch.tensor(val_preds), torch.tensor(val_labels))\n        val_f1 = f1_score(val_labels, val_preds, average='weighted')\n\n        avg_val_loss = running_val_loss / len(val_loader)\n        print(f\"Val Loss: {avg_val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%, Val F1: {val_f1:.4f}\")\n\n        # Save the best model based on validation F1 score\n        if val_f1 > best_val_f1:\n            best_val_f1 = val_f1\n            best_model_weights = model.state_dict()\n            epochs_since_improvement = 0  # Reset patience counter\n            print(f\"Saved best model with validation F1: {val_f1:.4f}\")\n        else:\n            epochs_since_improvement += 1\n            \n        # Early stopping check\n        if epochs_since_improvement >= patience:\n            print(f\"Stopping training early at epoch {epoch+1} due to no improvement in validation F1.\")\n            break\n\n    # Load best model weights\n    if best_model_weights:\n        model.load_state_dict(best_model_weights)\n\n    print(f\"Training Complete. Best Validation F1 Score: {best_val_f1:.4f}\")\n    return model, best_val_f1\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T17:31:51.466370Z","iopub.execute_input":"2024-11-27T17:31:51.466641Z","iopub.status.idle":"2024-11-27T17:31:51.484423Z","shell.execute_reply.started":"2024-11-27T17:31:51.466614Z","shell.execute_reply":"2024-11-27T17:31:51.483380Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"## Evaluating Test and Saving Predictions to CSV","metadata":{}},{"cell_type":"code","source":"\ndef evaluate_and_save_predictions(model, test_loader, output_csv='21F1000641.csv'):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model.to(device)  # Ensure model is on the correct device\n    model.eval()  # Set model to evaluation mode\n    predictions = []\n    image_ids = []\n    \n    # Disable gradient computation for inference\n    with torch.no_grad():\n        for inputs, paths in tqdm(test_loader):  # Assuming test_loader provides file paths\n            inputs = inputs.to(device)\n            \n            # Forward pass\n            outputs = model(inputs)\n            _, preds = torch.max(outputs, 1)\n            \n            # Extract Image_IDs (file names without extension)\n            for path, pred in zip(paths, preds):\n                image_id = os.path.splitext(os.path.basename(path))[0]  # Remove extension from the filename\n                predictions.append(pred.item())  # Add the predicted label\n                image_ids.append(image_id)  # Add the image ID\n\n    # Create a DataFrame with Image_ID and predicted labels\n    submission_df = pd.DataFrame({\n        'Image_ID': image_ids,\n        'Label': predictions\n    })\n    \n    # Save the DataFrame to a CSV file\n    output_csv_path = f\"/kaggle/working/{output_csv}\"\n    submission_df.to_csv(output_csv_path, index=False)\n    print(f\"Predictions saved to {output_csv_path}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T17:31:51.485687Z","iopub.execute_input":"2024-11-27T17:31:51.486048Z","iopub.status.idle":"2024-11-27T17:31:51.503160Z","shell.execute_reply.started":"2024-11-27T17:31:51.486009Z","shell.execute_reply":"2024-11-27T17:31:51.502110Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# Load EfficientNet-V2 pretrained model\nmodel = models.efficientnet_v2_s(pretrained=True)\n\n# Modify the final fully connected layer for custom number of output classes\nmodel.classifier[1] = nn.Linear(model.classifier[1].in_features, 10)  # 10 classes\n\n# Training the model\nprint(\"Training EfficientNet-V2:\")\ntrained_model, best_f1 = train_model(model, train_loader, val_loader, num_epochs=30, learning_rate=0.0001)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T17:31:51.987701Z","iopub.execute_input":"2024-11-27T17:31:51.988577Z","iopub.status.idle":"2024-11-27T18:03:36.809401Z","shell.execute_reply.started":"2024-11-27T17:31:51.988539Z","shell.execute_reply":"2024-11-27T18:03:36.808297Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_V2_S_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_V2_S_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"Training EfficientNet-V2:\nEpoch 1/30\n--------------------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 141/141 [04:18<00:00,  1.83s/it]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.9687, Train Accuracy: 72.89%, Train F1: 0.7285\nVal Loss: 0.4176, Val Accuracy: 87.30%, Val F1: 0.8732\nSaved best model with validation F1: 0.8732\nEpoch 2/30\n--------------------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 141/141 [03:36<00:00,  1.53s/it]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.3567, Train Accuracy: 89.39%, Train F1: 0.8940\nVal Loss: 0.3748, Val Accuracy: 88.60%, Val F1: 0.8860\nSaved best model with validation F1: 0.8860\nEpoch 3/30\n--------------------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 141/141 [03:36<00:00,  1.53s/it]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.2393, Train Accuracy: 92.75%, Train F1: 0.9276\nVal Loss: 0.3723, Val Accuracy: 89.90%, Val F1: 0.8989\nSaved best model with validation F1: 0.8989\nEpoch 4/30\n--------------------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 141/141 [03:38<00:00,  1.55s/it]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.1719, Train Accuracy: 94.92%, Train F1: 0.9492\nVal Loss: 0.3405, Val Accuracy: 89.90%, Val F1: 0.8987\nEpoch 5/30\n--------------------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 141/141 [03:36<00:00,  1.53s/it]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.1251, Train Accuracy: 96.23%, Train F1: 0.9623\nVal Loss: 0.4021, Val Accuracy: 89.00%, Val F1: 0.8898\nEpoch 6/30\n--------------------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 141/141 [03:37<00:00,  1.54s/it]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0987, Train Accuracy: 97.09%, Train F1: 0.9709\nVal Loss: 0.4285, Val Accuracy: 88.80%, Val F1: 0.8880\nEpoch 7/30\n--------------------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 141/141 [03:37<00:00,  1.54s/it]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0911, Train Accuracy: 97.22%, Train F1: 0.9722\nVal Loss: 0.4398, Val Accuracy: 89.30%, Val F1: 0.8927\nEpoch 8/30\n--------------------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 141/141 [03:37<00:00,  1.54s/it]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0780, Train Accuracy: 97.54%, Train F1: 0.9754\nVal Loss: 0.4630, Val Accuracy: 87.70%, Val F1: 0.8768\nStopping training early at epoch 8 due to no improvement in validation F1.\nTraining Complete. Best Validation F1 Score: 0.8989\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"evaluate_and_save_predictions(trained_model, test_loader, output_csv='21F1000641.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T18:05:31.948496Z","iopub.execute_input":"2024-11-27T18:05:31.949418Z","iopub.status.idle":"2024-11-27T18:06:13.982335Z","shell.execute_reply.started":"2024-11-27T18:05:31.949381Z","shell.execute_reply":"2024-11-27T18:06:13.981372Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 32/32 [00:41<00:00,  1.31s/it]","output_type":"stream"},{"name":"stdout","text":"Predictions saved to /kaggle/working/21F1000641.csv\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# model = models.regnet_y_8gf(pretrained=True)\n\n# # Modify the final fully connected layer for custom number of output classes\n# model.fc = nn.Linear(model.fc.in_features, 10)  # 10 classes\n\n\n# # Training the model\n# print(\"Training RegNetY-8GF:\")\n# trained_model, best_f1 = train_model(model, train_loader, val_loader, num_epochs=30, learning_rate=0.001)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Load VGG16 pretrained model\n# model = models.vgg16(pretrained=True)\n\n# # Modify the final fully connected layer for custom number of output classes\n# model.classifier[6] = nn.Linear(model.classifier[6].in_features, 10)  # 10 classes\n\n# # Training the model\n# print(\"Training VGG16:\")\n# trained_model, best_f1 = train_model(model, train_loader, val_loader, num_epochs=30, learning_rate=0.001)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# model1 = resnet18(pretrained=True)\n# model1.fc = nn.Linear(model1.fc.in_features, 10)  # Modify final FC layer for 10 classes\n# print(\"Training ResNet-18:\")\n# trained_model1, best_f1_model1 = train_model(model1, train_loader, val_loader, num_epochs=30, learning_rate=0.001)\n# print(f\"Best F1 Score for ResNet-18: {best_f1_model1}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# evaluate_and_save_predictions(trained_model1, test_loader, output_csv='21F1000641.csv')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\noutput_df = pd.read_csv(\"/kaggle/working/21F1000641.csv\")\nprint(len(output_df))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T18:06:38.465961Z","iopub.execute_input":"2024-11-27T18:06:38.466308Z","iopub.status.idle":"2024-11-27T18:06:38.474654Z","shell.execute_reply.started":"2024-11-27T18:06:38.466277Z","shell.execute_reply":"2024-11-27T18:06:38.473642Z"}},"outputs":[{"name":"stdout","text":"2000\n","output_type":"stream"}],"execution_count":14}]}