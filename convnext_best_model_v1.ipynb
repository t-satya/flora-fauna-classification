{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a67f5b68",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-08-03T09:59:58.939150Z",
     "iopub.status.busy": "2025-08-03T09:59:58.938778Z",
     "iopub.status.idle": "2025-08-03T10:00:00.247541Z",
     "shell.execute_reply": "2025-08-03T10:00:00.246640Z"
    },
    "papermill": {
     "duration": 1.315989,
     "end_time": "2025-08-03T10:00:00.249660",
     "exception": false,
     "start_time": "2025-08-03T09:59:58.933671",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd719f0",
   "metadata": {
    "papermill": {
     "duration": 0.003147,
     "end_time": "2025-08-03T10:00:00.256530",
     "exception": false,
     "start_time": "2025-08-03T10:00:00.253383",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ef107db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T10:00:00.263763Z",
     "iopub.status.busy": "2025-08-03T10:00:00.263360Z",
     "iopub.status.idle": "2025-08-03T10:00:12.625775Z",
     "shell.execute_reply": "2025-08-03T10:00:12.624867Z"
    },
    "papermill": {
     "duration": 12.367944,
     "end_time": "2025-08-03T10:00:12.627518",
     "exception": false,
     "start_time": "2025-08-03T10:00:00.259574",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x782fa7ec2d70>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imports necessary for training the model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms.v2 as transforms\n",
    "import torchvision.utils as utils\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Few other important libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import timm\n",
    "\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4737b0fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T10:00:12.636229Z",
     "iopub.status.busy": "2025-08-03T10:00:12.635968Z",
     "iopub.status.idle": "2025-08-03T10:00:12.639707Z",
     "shell.execute_reply": "2025-08-03T10:00:12.638909Z"
    },
    "papermill": {
     "duration": 0.01031,
     "end_time": "2025-08-03T10:00:12.641245",
     "exception": false,
     "start_time": "2025-08-03T10:00:12.630935",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d59d4cd",
   "metadata": {
    "papermill": {
     "duration": 0.003033,
     "end_time": "2025-08-03T10:00:12.647485",
     "exception": false,
     "start_time": "2025-08-03T10:00:12.644452",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7069987",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T10:00:12.655220Z",
     "iopub.status.busy": "2025-08-03T10:00:12.654968Z",
     "iopub.status.idle": "2025-08-03T10:00:12.685528Z",
     "shell.execute_reply": "2025-08-03T10:00:12.684957Z"
    },
    "papermill": {
     "duration": 0.03655,
     "end_time": "2025-08-03T10:00:12.687231",
     "exception": false,
     "start_time": "2025-08-03T10:00:12.650681",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "from timm.data import create_transform\n",
    "\n",
    "transform_train = create_transform(\n",
    "    input_size=(3, 224, 224),\n",
    "    is_training=True,\n",
    "    auto_augment='rand-m9-mstd0.5-inc1',  # optional but strong\n",
    "    interpolation='bicubic',\n",
    "    re_prob=0.25\n",
    ")\n",
    "\n",
    "transform_test = create_transform(\n",
    "    input_size=(3, 224, 224),\n",
    "    is_training=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ac49b4",
   "metadata": {
    "papermill": {
     "duration": 0.002924,
     "end_time": "2025-08-03T10:00:12.693301",
     "exception": false,
     "start_time": "2025-08-03T10:00:12.690377",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38e580bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T10:00:12.700805Z",
     "iopub.status.busy": "2025-08-03T10:00:12.700533Z",
     "iopub.status.idle": "2025-08-03T10:00:12.740226Z",
     "shell.execute_reply": "2025-08-03T10:00:12.739663Z"
    },
    "papermill": {
     "duration": 0.045254,
     "end_time": "2025-08-03T10:00:12.741847",
     "exception": false,
     "start_time": "2025-08-03T10:00:12.696593",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_path = \"/kaggle/input/deep-learning-practice-image-classification/train\"\n",
    "test_path = \"/kaggle/input/deep-learning-practice-image-classification/test\"\n",
    "\n",
    "\n",
    "from PIL import Image  # Import the Image module from Pillow\n",
    "\n",
    "class CustomTestDataset(Dataset):\n",
    "    def __init__(self, test_dir, transform=None):\n",
    "        self.test_dir = test_dir\n",
    "        self.transform = transform\n",
    "        self.image_paths = [os.path.join(test_dir, fname) for fname in os.listdir(test_dir)]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")  # Open image and convert to RGB\n",
    "        if self.transform:\n",
    "            image = self.transform(image)  # Apply the transform if available\n",
    "        return image, img_path  # Return the image and its path\n",
    "\n",
    "\n",
    "# Create test data\n",
    "test_data = CustomTestDataset(test_dir=test_path, transform=transform_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9701def3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T10:00:12.749087Z",
     "iopub.status.busy": "2025-08-03T10:00:12.748838Z",
     "iopub.status.idle": "2025-08-03T10:00:27.462223Z",
     "shell.execute_reply": "2025-08-03T10:00:27.461096Z"
    },
    "papermill": {
     "duration": 14.719015,
     "end_time": "2025-08-03T10:00:27.464011",
     "exception": false,
     "start_time": "2025-08-03T10:00:12.744996",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Shape:  9999\n",
      "Test Data Shape:  2000\n"
     ]
    }
   ],
   "source": [
    "# Load Training and Test datasets\n",
    "full_train_data = dsets.ImageFolder(root=train_path)\n",
    "\n",
    "# Create a validation set from the training data\n",
    "train_size_fraction = 0.9\n",
    "train_size = int(train_size_fraction*len(full_train_data))  # 90% for training\n",
    "val_size = len(full_train_data) - train_size  # 10% for validation\n",
    "train_dataset, val_dataset = random_split(full_train_data, [train_size, val_size])\n",
    "\n",
    "# Now apply transform_train and transform_test separately\n",
    "train_dataset.dataset.transform = transform_train  # augmentation\n",
    "val_dataset.dataset.transform = transform_test      # no augmentation\n",
    "\n",
    "# Print data details\n",
    "print(\"Train Data Shape: \", len(full_train_data))\n",
    "print(\"Test Data Shape: \", len(test_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0481007",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T10:00:27.472148Z",
     "iopub.status.busy": "2025-08-03T10:00:27.471513Z",
     "iopub.status.idle": "2025-08-03T10:00:27.475846Z",
     "shell.execute_reply": "2025-08-03T10:00:27.475022Z"
    },
    "papermill": {
     "duration": 0.009939,
     "end_time": "2025-08-03T10:00:27.477342",
     "exception": false,
     "start_time": "2025-08-03T10:00:27.467403",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label_mapping {'Amphibia': 0, 'Animalia': 1, 'Arachnida': 2, 'Aves': 3, 'Fungi': 4, 'Insecta': 5, 'Mammalia': 6, 'Mollusca': 7, 'Plantae': 8, 'Reptilia': 9}\n"
     ]
    }
   ],
   "source": [
    "print(\"label_mapping\",full_train_data.class_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83e503ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T10:00:27.484612Z",
     "iopub.status.busy": "2025-08-03T10:00:27.484369Z",
     "iopub.status.idle": "2025-08-03T10:00:27.490348Z",
     "shell.execute_reply": "2025-08-03T10:00:27.489464Z"
    },
    "papermill": {
     "duration": 0.011368,
     "end_time": "2025-08-03T10:00:27.491894",
     "exception": false,
     "start_time": "2025-08-03T10:00:27.480526",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of samples in training dataset: 8999\n",
      "No. of samples in validation dataset: 1000\n",
      "No. of samples in test dataset: 2000\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64 # Batch Size of the images\n",
    "\n",
    "# Creating dataloaders\n",
    "train_loader = DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle = True,num_workers=2)\n",
    "val_loader = DataLoader(dataset = val_dataset, batch_size = batch_size, shuffle = False,num_workers=2)\n",
    "test_loader = DataLoader(dataset = test_data, batch_size = batch_size, shuffle = False,num_workers=2)\n",
    "\n",
    "# Printing the no. of samples in each dataset\n",
    "print(\"No. of samples in training dataset:\", len(train_loader.dataset))\n",
    "print(\"No. of samples in validation dataset:\", len(val_loader.dataset))\n",
    "print(\"No. of samples in test dataset:\", len(test_loader.dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9968ed64",
   "metadata": {
    "papermill": {
     "duration": 0.003161,
     "end_time": "2025-08-03T10:00:27.498369",
     "exception": false,
     "start_time": "2025-08-03T10:00:27.495208",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training and Validating Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02be70a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T10:00:27.506206Z",
     "iopub.status.busy": "2025-08-03T10:00:27.505983Z",
     "iopub.status.idle": "2025-08-03T10:00:27.518675Z",
     "shell.execute_reply": "2025-08-03T10:00:27.518033Z"
    },
    "papermill": {
     "duration": 0.018647,
     "end_time": "2025-08-03T10:00:27.520235",
     "exception": false,
     "start_time": "2025-08-03T10:00:27.501588",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "# Function to calculate accuracy\n",
    "def calculate_accuracy(preds, labels):\n",
    "    correct = (preds == labels).sum().item()\n",
    "    return correct / len(labels) * 100\n",
    "\n",
    "# Define the training function\n",
    "def train_model(model, train_loader, val_loader, num_epochs=10, learning_rate=0.0001,patience=2):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Loss function\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    optimizer = AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=learning_rate, weight_decay=1e-4)\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
    "\n",
    "    best_val_f1 = 0.0  # Track the best F1 score\n",
    "    best_model_weights = None  # Store best model weights\n",
    "    \n",
    "    scaler = GradScaler()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "        print(\"-\" * 20)\n",
    "        \n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        all_train_preds = []\n",
    "        all_train_labels = []\n",
    "\n",
    "        for inputs, labels in tqdm(train_loader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with autocast():\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            # Get predictions\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            running_corrects += (preds == labels).sum().item()\n",
    "\n",
    "            all_train_preds.extend(preds.cpu().numpy())\n",
    "            all_train_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        # Calculate training accuracy and F1 score\n",
    "        train_accuracy = calculate_accuracy(torch.tensor(all_train_preds), torch.tensor(all_train_labels))\n",
    "        train_f1 = f1_score(all_train_labels, all_train_preds, average='weighted')\n",
    "\n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "        print(f\"Train Loss: {avg_train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, Train F1: {train_f1:.4f}\")\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_preds = []\n",
    "        val_labels = []\n",
    "        running_val_loss = 0.0\n",
    "        running_val_corrects = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                running_val_loss += loss.item()\n",
    "                running_val_corrects += (preds == labels).sum().item()\n",
    "\n",
    "                val_preds.extend(preds.cpu().numpy())\n",
    "                val_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        # Calculate validation accuracy and F1 score\n",
    "        val_accuracy = calculate_accuracy(torch.tensor(val_preds), torch.tensor(val_labels))\n",
    "        val_f1 = f1_score(val_labels, val_preds, average='weighted')\n",
    "\n",
    "        avg_val_loss = running_val_loss / len(val_loader)\n",
    "        print(f\"Val Loss: {avg_val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%, Val F1: {val_f1:.4f}\")\n",
    "        \n",
    "        # Step the learning rate scheduler\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Save the best model based on validation F1 score\n",
    "        if val_f1 > best_val_f1:\n",
    "            best_val_f1 = val_f1\n",
    "            best_model_weights = model.state_dict()\n",
    "            epochs_since_improvement = 0  # Reset patience counter\n",
    "            print(f\"Saved best model with validation F1: {val_f1:.4f}\")\n",
    "        else:\n",
    "            epochs_since_improvement += 1\n",
    "            \n",
    "        # Early stopping check\n",
    "        if epochs_since_improvement >= patience:\n",
    "            print(f\"Stopping training early at epoch {epoch+1} due to no improvement in validation F1.\")\n",
    "            break\n",
    "\n",
    "    # Load best model weights\n",
    "    if best_model_weights:\n",
    "        model.load_state_dict(best_model_weights)\n",
    "\n",
    "    print(f\"Training Complete. Best Validation F1 Score: {best_val_f1:.4f}\")\n",
    "    return model, best_val_f1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef91811",
   "metadata": {
    "papermill": {
     "duration": 0.003112,
     "end_time": "2025-08-03T10:00:27.526555",
     "exception": false,
     "start_time": "2025-08-03T10:00:27.523443",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Evaluating Test and Saving Predictions to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "737e306d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T10:00:27.533855Z",
     "iopub.status.busy": "2025-08-03T10:00:27.533618Z",
     "iopub.status.idle": "2025-08-03T10:00:27.539519Z",
     "shell.execute_reply": "2025-08-03T10:00:27.538788Z"
    },
    "papermill": {
     "duration": 0.011246,
     "end_time": "2025-08-03T10:00:27.541066",
     "exception": false,
     "start_time": "2025-08-03T10:00:27.529820",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_and_save_predictions(model, test_loader, output_csv='21F1000641.csv'):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)  # Ensure model is on the correct device\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    predictions = []\n",
    "    image_ids = []\n",
    "    \n",
    "    # Disable gradient computation for inference\n",
    "    with torch.no_grad():\n",
    "        for inputs, paths in tqdm(test_loader):  # Assuming test_loader provides file paths\n",
    "            inputs = inputs.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            # Extract Image_IDs (file names without extension)\n",
    "            for path, pred in zip(paths, preds):\n",
    "                image_id = os.path.splitext(os.path.basename(path))[0]  # Remove extension from the filename\n",
    "                predictions.append(pred.item())  # Add the predicted label\n",
    "                image_ids.append(image_id)  # Add the image ID\n",
    "\n",
    "    # Create a DataFrame with Image_ID and predicted labels\n",
    "    submission_df = pd.DataFrame({\n",
    "        'Image_ID': image_ids,\n",
    "        'Label': predictions\n",
    "    })\n",
    "    \n",
    "    # Save the DataFrame to a CSV file\n",
    "    output_csv_path = f\"/kaggle/working/{output_csv}\"\n",
    "    submission_df.to_csv(output_csv_path, index=False)\n",
    "    print(f\"Predictions saved to {output_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93eea1b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T10:00:27.548855Z",
     "iopub.status.busy": "2025-08-03T10:00:27.548336Z",
     "iopub.status.idle": "2025-08-03T10:18:00.543687Z",
     "shell.execute_reply": "2025-08-03T10:18:00.542589Z"
    },
    "papermill": {
     "duration": 1053.096084,
     "end_time": "2025-08-03T10:18:00.640448",
     "exception": false,
     "start_time": "2025-08-03T10:00:27.544364",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b9b23d0488b450686e5901d6ed3b7b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/114M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ConvNext :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23/3625680109.py:24: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/141 [00:00<?, ?it/s]/tmp/ipykernel_23/3625680109.py:42: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "100%|██████████| 141/141 [01:32<00:00,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.5561, Train Accuracy: 54.92%, Train F1: 0.5459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.9386, Val Accuracy: 81.80%, Val F1: 0.8172\n",
      "Saved best model with validation F1: 0.8172\n",
      "Epoch 2/30\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/141 [00:00<?, ?it/s]/tmp/ipykernel_23/3625680109.py:42: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "100%|██████████| 141/141 [01:00<00:00,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7057, Train Accuracy: 85.68%, Train F1: 0.8566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.5815, Val Accuracy: 88.70%, Val F1: 0.8869\n",
      "Saved best model with validation F1: 0.8869\n",
      "Epoch 3/30\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/141 [00:00<?, ?it/s]/tmp/ipykernel_23/3625680109.py:42: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "100%|██████████| 141/141 [00:59<00:00,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4915, Train Accuracy: 89.41%, Train F1: 0.8942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.4580, Val Accuracy: 89.50%, Val F1: 0.8949\n",
      "Saved best model with validation F1: 0.8949\n",
      "Epoch 4/30\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/141 [00:00<?, ?it/s]/tmp/ipykernel_23/3625680109.py:42: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "100%|██████████| 141/141 [01:01<00:00,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4014, Train Accuracy: 90.91%, Train F1: 0.9092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.3978, Val Accuracy: 90.20%, Val F1: 0.9018\n",
      "Saved best model with validation F1: 0.9018\n",
      "Epoch 5/30\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/141 [00:00<?, ?it/s]/tmp/ipykernel_23/3625680109.py:42: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "100%|██████████| 141/141 [01:00<00:00,  2.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3507, Train Accuracy: 91.60%, Train F1: 0.9160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.3628, Val Accuracy: 90.90%, Val F1: 0.9087\n",
      "Saved best model with validation F1: 0.9087\n",
      "Epoch 6/30\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/141 [00:00<?, ?it/s]/tmp/ipykernel_23/3625680109.py:42: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "100%|██████████| 141/141 [00:59<00:00,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3182, Train Accuracy: 92.17%, Train F1: 0.9217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.3413, Val Accuracy: 91.40%, Val F1: 0.9137\n",
      "Saved best model with validation F1: 0.9137\n",
      "Epoch 7/30\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/141 [00:00<?, ?it/s]/tmp/ipykernel_23/3625680109.py:42: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "100%|██████████| 141/141 [01:00<00:00,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2959, Train Accuracy: 92.48%, Train F1: 0.9248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.3260, Val Accuracy: 91.50%, Val F1: 0.9147\n",
      "Saved best model with validation F1: 0.9147\n",
      "Epoch 8/30\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/141 [00:00<?, ?it/s]/tmp/ipykernel_23/3625680109.py:42: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "100%|██████████| 141/141 [01:00<00:00,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2781, Train Accuracy: 92.97%, Train F1: 0.9297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.3156, Val Accuracy: 91.80%, Val F1: 0.9177\n",
      "Saved best model with validation F1: 0.9177\n",
      "Epoch 9/30\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/141 [00:00<?, ?it/s]/tmp/ipykernel_23/3625680109.py:42: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "100%|██████████| 141/141 [00:59<00:00,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2637, Train Accuracy: 93.05%, Train F1: 0.9305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.3069, Val Accuracy: 91.90%, Val F1: 0.9189\n",
      "Saved best model with validation F1: 0.9189\n",
      "Epoch 10/30\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/141 [00:00<?, ?it/s]/tmp/ipykernel_23/3625680109.py:42: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "100%|██████████| 141/141 [00:59<00:00,  2.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2528, Train Accuracy: 93.39%, Train F1: 0.9339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.3002, Val Accuracy: 92.30%, Val F1: 0.9229\n",
      "Saved best model with validation F1: 0.9229\n",
      "Epoch 11/30\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/141 [00:00<?, ?it/s]/tmp/ipykernel_23/3625680109.py:42: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "100%|██████████| 141/141 [00:59<00:00,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2428, Train Accuracy: 93.59%, Train F1: 0.9359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.2954, Val Accuracy: 92.50%, Val F1: 0.9250\n",
      "Saved best model with validation F1: 0.9250\n",
      "Epoch 12/30\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/141 [00:00<?, ?it/s]/tmp/ipykernel_23/3625680109.py:42: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "100%|██████████| 141/141 [00:59<00:00,  2.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2345, Train Accuracy: 93.83%, Train F1: 0.9383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.2913, Val Accuracy: 92.60%, Val F1: 0.9260\n",
      "Saved best model with validation F1: 0.9260\n",
      "Epoch 13/30\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/141 [00:00<?, ?it/s]/tmp/ipykernel_23/3625680109.py:42: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "100%|██████████| 141/141 [00:59<00:00,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2275, Train Accuracy: 94.02%, Train F1: 0.9402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.2885, Val Accuracy: 92.80%, Val F1: 0.9280\n",
      "Saved best model with validation F1: 0.9280\n",
      "Epoch 14/30\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/141 [00:00<?, ?it/s]/tmp/ipykernel_23/3625680109.py:42: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "100%|██████████| 141/141 [00:59<00:00,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2211, Train Accuracy: 94.07%, Train F1: 0.9407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.2857, Val Accuracy: 92.70%, Val F1: 0.9270\n",
      "Epoch 15/30\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/141 [00:00<?, ?it/s]/tmp/ipykernel_23/3625680109.py:42: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "100%|██████████| 141/141 [00:58<00:00,  2.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2157, Train Accuracy: 94.25%, Train F1: 0.9425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.2837, Val Accuracy: 92.70%, Val F1: 0.9269\n",
      "Stopping training early at epoch 15 due to no improvement in validation F1.\n",
      "Training Complete. Best Validation F1 Score: 0.9280\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = timm.create_model('convnext_tiny', pretrained=True, num_classes=10)\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    if 'head' not in name:\n",
    "        param.requires_grad = False\n",
    "\n",
    "# Training the model\n",
    "print(\"Training ConvNext :\")\n",
    "trained_model, best_f1 = train_model(model, train_loader, val_loader, num_epochs=30, learning_rate=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c0d63b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T10:18:00.831133Z",
     "iopub.status.busy": "2025-08-03T10:18:00.830799Z",
     "iopub.status.idle": "2025-08-03T10:18:23.203902Z",
     "shell.execute_reply": "2025-08-03T10:18:23.202852Z"
    },
    "papermill": {
     "duration": 22.46993,
     "end_time": "2025-08-03T10:18:23.206113",
     "exception": false,
     "start_time": "2025-08-03T10:18:00.736183",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:22<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to /kaggle/working/21F1000641.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_and_save_predictions(trained_model, test_loader, output_csv='21F1000641.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d16a763b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T10:18:23.399763Z",
     "iopub.status.busy": "2025-08-03T10:18:23.399401Z",
     "iopub.status.idle": "2025-08-03T10:18:23.414697Z",
     "shell.execute_reply": "2025-08-03T10:18:23.413936Z"
    },
    "papermill": {
     "duration": 0.11326,
     "end_time": "2025-08-03T10:18:23.416355",
     "exception": false,
     "start_time": "2025-08-03T10:18:23.303095",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "output_df = pd.read_csv(\"/kaggle/working/21F1000641.csv\")\n",
    "print(len(output_df))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 9549185,
     "sourceId": 84763,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1111.733786,
   "end_time": "2025-08-03T10:18:26.989966",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-08-03T09:59:55.256180",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "2abd26464a204a38a76749681c6c5146": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3600cb90955a48a5954fa6e4a32f8ff4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5b36026727054f2aa9b1797cdfa54f8c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "68523daf1b3e4f51966cf49a56782be1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6b9b23d0488b450686e5901d6ed3b7b2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_90b1579f0f504957be80160a4dfdb77b",
        "IPY_MODEL_e9a39e1875d24fbfb6dd58248ca185ea",
        "IPY_MODEL_9d1af5ac06e24bbbac79360d2b5da0de"
       ],
       "layout": "IPY_MODEL_68523daf1b3e4f51966cf49a56782be1"
      }
     },
     "8be3dd5ed79e41e3bdfac3b166172c97": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "90b1579f0f504957be80160a4dfdb77b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_c19995d10547401f8bebd421de82a642",
       "placeholder": "​",
       "style": "IPY_MODEL_8be3dd5ed79e41e3bdfac3b166172c97",
       "value": "model.safetensors: 100%"
      }
     },
     "9d1af5ac06e24bbbac79360d2b5da0de": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_3600cb90955a48a5954fa6e4a32f8ff4",
       "placeholder": "​",
       "style": "IPY_MODEL_5b36026727054f2aa9b1797cdfa54f8c",
       "value": " 114M/114M [00:00&lt;00:00, 142MB/s]"
      }
     },
     "c19995d10547401f8bebd421de82a642": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "da16c0a267524488b0c88163d0c2748f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "e9a39e1875d24fbfb6dd58248ca185ea": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_2abd26464a204a38a76749681c6c5146",
       "max": 114374272.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_da16c0a267524488b0c88163d0c2748f",
       "value": 114374272.0
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
